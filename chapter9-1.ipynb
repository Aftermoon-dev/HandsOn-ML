{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72361e4c",
   "metadata": {},
   "source": [
    "# 9. 비지도 학습\n",
    "- 훈련 데이터에 레이블이 존재하지 않아 시스템이 아무런 도움 없이 학습해야 하는 학습 방법\n",
    "- 9장에서 다루는 비지도 학습 알고리즘\n",
    "    1. 군집 (Clustering)\n",
    "     - 비슷한 샘플을 **클러스터 (Cluster)**로 모음\n",
    "     - 데이터 분석, 고객 분류, 추천 시스템, 검색 엔진, 이미지 분할, 준지도 학습, 차원 축소 등에 사용할 수 있는 훌륭한 도구\n",
    "\n",
    "    2. 이상치 탐지 (Outliner Detection)\n",
    "     - '정상' 데이터가 어떻게 보이는지를 학습하고 비정상 샘플을 감지하는데 사용\n",
    "     - 제조 라인에서 결함 제품 감지, 시계열 데이터에서 새로운 트렌드 찾기 등\n",
    "\n",
    "    3. 밀도 추정 (Density Estimation)\n",
    "     - 데이터셋 생성 확률 과정의 **확률 밀도 함수 (PDF)**를 추정\n",
    "     - 밀도 추정은 이상치 탐지에 널리 사용됨\n",
    "         * 밀도가 매우 낮은 영역에 놓인 샘플이 이상치일 가능성이 높음\n",
    "     - 데이터 분석과 시각화에도 유용함\n",
    "\n",
    "## 9.1 군집\n",
    "- 비슷한 샘플을 구별해 하나의 **클러스터 (Cluster)** 또는 비슷한 샘플의 그룹으로 할당하는 작업\n",
    "- [그림 9-1]은 붓꽃 데이터셋을 이용한 분류와 군집 알고리즘 비교를 나타냄\n",
    "    * 왼쪽은 각 샘플의 품종 (클래스)가 구분되어 나타남 (레이블링이 되어있다)\n",
    "    * 오른쪽은 동일한 데이터셋이지만 레이블이 존재하지 않음\n",
    "        - 레이블링이 되어있지 않아 분류 알고리즘을 사용할 수 없음\n",
    "        - 군집 알고리즘을 사용하여 분류해야 함\n",
    "       \n",
    "       \n",
    "- 군집을 사용하는 다양한 애플리케이션\n",
    "    1. 고객 분류\n",
    "        - 고객을 구매 이력이나 웹사이트 내 행동 기반으로 클러스터로 모음\n",
    "        - 고객이 누구인지, 무엇을 원하는지 이해하는데 도움\n",
    "        - 고객 그룹마다 제품 추천이나 마케팅 전략을 다르게 적용할 수 있음\n",
    "            * ex. 동일한 클러스터 내의 사용자가 좋아하는 컨텐츠를 추천하는 **추천 시스템**\n",
    "            \n",
    "    2. 데이터 분석\n",
    "        - 새로운 데이터셋을 분석할 때 군집 알고리즘을 실행하고 각 클러스터를 따로 분석하면 도움이 됨\n",
    "        \n",
    "    3. 차원 축소 기법\n",
    "        - 한 데이터셋에 군집 알고리즘을 적용하면 각 클러스터에 대한 샘플의 **친화성 (Affinity)**을 측정할 수 있음\n",
    "            * 친화성 : 샘플이 클러스터에 얼마나 잘 맞는가?\n",
    "        - 각 샘플의 특성 벡터 x는 클러스터 친화성의 벡터로 바꿀 수 있음\n",
    "            - k개의 클러스터가 있다면 이 벡터는 k차원이 됨\n",
    "            - 일반적으로 원본 특성 벡터보다 훨씬 저차원 \n",
    "            - 그러나 이후 분석을 위한 충분한 정보를 가질 수 있음\n",
    "            \n",
    "    4. 이상치 탐지\n",
    "        - 모든 클러스터에 친화성이 낮은 샘플은 이상치일 가능성이 높음\n",
    "        - 웹사이트 내 행동을 기반으로 사용자의 클러스터를 만들었다면 초당 웹서버 요청을 비정상적으로 많이 하는 사용자가 ㅁ지 가능\n",
    "        - 제조 분야에서 결함을 감지할 때 유용 (또는 **부정 거래 감지**에 활용됨)\n",
    "        \n",
    "    5. 준지도 학습\n",
    "        - 레이블된 샘플이 적다면 군집을 수행하고 동일한 클러스터에 있는 모든 샘플에 레이블을 전파할 수 있음\n",
    "        - 이어지는 지도 학습 알고리즘에 필요한 레이블이 크게 증가하여 성능을 크게 향상시킴\n",
    "        \n",
    "    6. 검색 엔진\n",
    "        - 제시된 이미지와 비슷한 이미지를 찾는 검색 엔진을 구축하려면 데이터베이스에 있는 모든 이미지에 군집 알고리즘을 적용\n",
    "            * 비슷한 이미지는 동일한 클러스터에 속함\n",
    "        - 사용자가 찾으려는 이미지를 제공하면 훈련된 군집 모델을 사용해 이미지의 클러스터를 찾고, 이 클러스터의 모든 이미지를 반환\n",
    "        \n",
    "    7. 이미지 분할\n",
    "        - 색을 기반으로 픽셀을 클러스터로 모은 다음, 각 픽셀의 색을 해당 클러스터의 평균 색으로 바꿈\n",
    "            * 이미지에 있는 색상의 종류를 크게 줄이게 됨\n",
    "        - 물체의 윤곽을 감지하기 쉬워 물체 탐지 및 추적 시스템에서 많이 사용함\n",
    "        \n",
    "- 클러스터에 대한 보편적인 정의는 없음\n",
    "    * 실제로 상황에 따라 다름 (알고리즘이 다르면 다른 종류의 클러스터를 감지)\n",
    "        1. **센트로이드 (Centroid)**라 부르는 특정 포인트를 중심으로 모인 샘플을 찾음\n",
    "        2. 샘플이 밀집되어 연속된 영역을 찾음\n",
    "            * 클러스터가 어떤 모양이든 될 수 있음\n",
    "        3. 계층적으로 클러스터의 클러스터를 찾음\n",
    "    * 유명한 군집 알고리즘 : k-평균과 DBSCAN\n",
    "    \n",
    "### 9.1.1 k-평균\n",
    "- [그림 9-2]에 있는 레이블 없는 데이터셋 살펴보기\n",
    "    * 샘플 덩어리 5개를 볼 수 있음\n",
    "- k-평균은 반복 몇 번으로 이런 종류의 데이터셋을 빠르고 효율적으로 클러스터로 묶을 수 있는 간단한 알고리즘\n",
    "    * 로이드-포지 알고리즘이라고 부르기도 함\n",
    "    \n",
    "- 위의 데이터셋에 k-평균 알고리즘 훈련해보기 \n",
    "    * 각 클러스터의 중심을 찾고 가장 가까운 클러스터에 샘플 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10bc5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 데이터 생성\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "blob_centers = np.array(\n",
    "    [[ 0.2,  2.3],\n",
    "     [-1.5 ,  2.3],\n",
    "     [-2.8,  1.8],\n",
    "     [-2.8,  2.8],\n",
    "     [-2.8,  1.3]])\n",
    "blob_std = np.array([0.4, 0.3, 0.1, 0.1, 0.1])\n",
    "X, y = make_blobs(n_samples=2000, centers=blob_centers,\n",
    "                  cluster_std=blob_std, random_state=7)\n",
    "\n",
    "# k-평균 알고리즘 훈련\n",
    "from sklearn.cluster import KMeans\n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "y_pred = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99769d67",
   "metadata": {},
   "source": [
    "- 알고리즘이 찾을 클러스터 갯수 k를 지정해야 함\n",
    "    * 이 예제에서는 데이터를 보고 k를 5로 지정해야 한다고 알 수 있음\n",
    "        - 그러나 일반적으로 쉬운 일이 아님\n",
    "- 각 샘플은 5개의 클러스터 중 하나에 할당됨\n",
    "- 군집에서 각 샘플의 **레이블**은 알고리즘이 샘플에 할당한 클러스터의 인덱스\n",
    "- *KMeans* 클래스의 인스턴스는 *labels_* 인스턴스 변수에 훈련된 샘플의 레이블을 가지고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3657e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 1, ..., 0, 1, 2], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b81e703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred is kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5031248f",
   "metadata": {},
   "source": [
    "- 이 알고리즘이 찾은 센트로이드 5개도 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0039d703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.79290307,  2.79641063],\n",
       "       [ 0.20876306,  2.25551336],\n",
       "       [-2.80389616,  1.80117999],\n",
       "       [-1.46679593,  2.28585348],\n",
       "       [-2.80037642,  1.30082566]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945941c6",
   "metadata": {},
   "source": [
    "- 새로운 샘플에 가장 가까운 센트로이드의 클러스터를 할당할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c60ed054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([[0, 2], [3, 2], [-3, 3], [-3, 2.5]])\n",
    "kmeans.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4952b7f",
   "metadata": {},
   "source": [
    "- 클러스터의 결정 경계를 그려보면 보노로이 다이어그램을 얻을 수 있음 (그림 9-3, 센트로이드는 X로 표시)\n",
    "\n",
    "\n",
    "- **샘플**은 대부분 적절한 클러스터에 잘 할당됨\n",
    "    * 그러나 몇 개는 레이블이 잘못 부여됨 (특히 왼쪽 위에 있는 클러스터와 가운데 클러스터의 경계 부근)\n",
    "- k-평균 알고리즘은 클러스터의 크기가 많이 다르면 잘 작동하지 않음\n",
    "    * 샘플을 클러스터에 할당할 때 센트로이드까지 거리를 고려하는 것이 전부이기 때문\n",
    "- **하드 군집**이라는 샘플을 하나의 클러스터에 할당하는 것보다 샘플에 점수를 부여하는 것이 유용할 수 있음\n",
    "    * 이를 **소프트 군집**이라고 함\n",
    "    * 이 점수는 샘플과 센트로이드 사이의 거리가 될 수 있고, 반대로 가우시안 방사기저 함수와 같은 유사도 점수 (또는 친화성 점수) 가 될 수 있음\n",
    "- *KMeans* 클래스의 *transform()* 메서드는 샘플과 각 센트로이드 사이의 거리를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c49591b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9042344 , 0.32995317, 2.81093633, 1.49439034, 2.88633901],\n",
       "       [5.84739223, 2.80290755, 5.80730058, 4.4759332 , 5.84236351],\n",
       "       [0.29040966, 3.29399768, 1.21475352, 1.69136631, 1.71086031],\n",
       "       [0.36159148, 3.21806371, 0.72581411, 1.54808703, 1.21567622]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26783a4",
   "metadata": {},
   "source": [
    "- 고차원 데이터셋을 이런 방식으로 변환하면 k-차원 데이터셋이 만들어짐\n",
    "    * 이러한 변환은 매우 효율적인 비선형 차원 축소 기법이 될 수 있음\n",
    "\n",
    "#### k-평균 알고리즘\n",
    "- 센트로이드가 주어진다고 가정했을 때, 데이터셋에 있는 모든 새믈에 가장 가까운 센트로이드의 클러스터 할당 가능\n",
    "- 반대로 모든 샘플의 레이블이 주어진다면 각 클러스터에 속한 샘플 평균을 계산하여 모든 센트로이드를 쉽게 구할 수 있음\n",
    "- 하지만 레이블이나 센트로이드가 주어지지 않는 경우에는?\n",
    "    * 처음에는 센트로이드를 랜덤하게 선정\n",
    "        - 예: 무작위로 k개의 샘플을 뽑아 그 위치를 센트로이드로 정함\n",
    "    * 그 다음 샘플에 레이블을 할당하고 센트로이드를 업데이트하는 과정을 반복해 센트로이드에 변화가 없을 때까지 계속함\n",
    "        - 이 알고리즘은 제한된 횟수 안에 수렴하는걸 보장 -> 무한 반복되지 않음 (일반적으로 이 횟수는 매우 작음)\n",
    "        - 샘플과 가장 가까운 센트로이드 사이의 평균 제곱 거리가 매 단계마다 작아질 수밖에 없기 때문\n",
    "- [그림 9-4]에서 이 알고리즘이 작동하는 것을 볼 수 있음\n",
    "    1. 처음에는 센트로이드를 랜덤하게 초기화 (왼쪽 위)\n",
    "    2. 그 다음 샘플에 레이블을 할당 (오른쪽 위)\n",
    "    3. 그 다음 센트로이드를 업데이트 (왼쪽 가운데)\n",
    "    4. 샘플에 다시 레이블 할당 (오른쪽 가운데)\n",
    "    5. 반복\n",
    "    \n",
    "    * 그림에서 볼 수 있듯 반복 세 번만에 이 알고리즘은 최적으로 보이는 클러스터에 도달\n",
    "\n",
    "- **NOTE** 이 알고리즘의 계산 복잡도는 일반적으로 샘플 개수 *m*, 클러스터 개수 *k*, 차원 개수 *n*에 선형적\n",
    "    * 그러나 이는 데이터가 군집할 수 있는 구조를 가질 때이며, 그렇지 않은 경우 최악의 경우 계산 복잡도는 샘플 개수가 지수적으로 급격히 증가할 수 있음\n",
    "    * 실전에서는 이런 일이 드뭄 (일반적으로 k-평균은 가장 빠른 군집 알고리즘 중 하나임)\n",
    "\n",
    "- 이 알고리즘이 수렴하는 것이 보장되지만 적절한 솔루션으로 수렴하지 못할 수 있음\n",
    "    * 즉 지역 최적점으로 수렴하게 될 수도 있음\n",
    "- 이러한 일의 여부는 센트로이드 초기화에 달려있음\n",
    "    * [그림 9-5]는 랜덤한 초기화 단계에 운이 없을 때 알고리즘이 수렴할 수 있는 최적이 아닌 솔루션의 두 예시\n",
    "    \n",
    "#### 센트로이드 초기화 방법\n",
    "- 센트로이드 위치를 근사하게 알 수 있다면 (ex. 또 다른 군집 알고리즘을 먼저 실행) *init* 매개변수에 센트로이드 리스트를 담은 넘파이 배열을 지정하고 *n_init*를 1로 설정할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5e49f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_init = np.array([[-3, 3], [-3, 2], [-3, 1], [-1, 2], [0, 2]])\n",
    "kmeans = KMeans(n_clusters=5, init=good_init, n_init=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b445abe3",
   "metadata": {},
   "source": [
    "- 또 다른 방법 : 랜덤 초기화를 다르게 하여 여러 번 알고리즘을 실행하고 가장 좋은 솔루션을 선택하는 것\n",
    "    * 랜덤 초기화 횟수는 *n_init* 매개변수를 조절 (기본값은 10)\n",
    "        - 이는 *fit()* 메서드를 호출할 때 앞서 설명한 전체 알고리즘이 10번 실행된다는 의미\n",
    "\n",
    "- Sklearn은 이 중에 최선의 솔루션을 반환함\n",
    "    * 어떻게 최선의 솔루션을 알 수 있는가?\n",
    "        - 각 샘플과 가장 가까운 센트로이드 사이의 평균 제곱 거리이며 **모델의 이너셔 (Inertia)**라고 부름\n",
    "\n",
    "- [그림 9-5]의 왼쪽 모델의 이너셔는 대략 223.3 - 오른쪽 모델의 이너셔는 237.5\n",
    "    * [그림 9-3]의 모델은 211.6\n",
    "    \n",
    "- KMeans 클래스는 알고리즘을 *n_init*번 실행하여 이너셔가 가장 낮은 모델을 반환\n",
    "    * 랜덤 초기화가 *n_init*번 연속으로 운이 나쁘지 않다면 [그림 9-3]에 있는 모델이 선택됨\n",
    "        - 이 값이 궁금하면 *inertia_* 인스턴스 변수로 모델의 이너셔를 확인할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28cf4644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211.59853725816836"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d76438",
   "metadata": {},
   "source": [
    "- *score()* 메서드는 이너셔의 음숫값을 반환함\n",
    "    * 음수인 이유 : 예측기의 *score()* 메서드는 사이킷런의 '큰 값이 좋은 것이다'라는 규칙을 따르기 때문\n",
    "    * 한 예측기가 다른 것보다 좋다면 *score()* 메서드가 더 높은 값을 반환해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d5458bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-211.5985372581684"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.score(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f132c81",
   "metadata": {},
   "source": [
    "- 데이비드 아서와 세르게이 바실비츠키가 2006년에 k-평균 알고리즘을 향상시킨 *k-평균++ 알고리즘*을 제안\n",
    "    * 다른 센트로이드와 거리가 먼 센트로이드를 선택하는 똑똑한 초기화 단계를 소개\n",
    "    * k-평균 알고리즘이 최적이 아닌 솔루션으로 수렴할 가능성을 크게 낮춤\n",
    "    * 최적의 솔루션을 찾기 위해 실행할 알고리즘 반복 횟수를 크게 줄일 수 있기 때문에 똑똑한 초기화 단계에 드는 추가 계산이 충분한 가치가 있다는 것을 보여줌\n",
    "        1. 데이터셋에서 무작위로 균등하게 하나의 센트로이드 $c^{(1)}$을 선택\n",
    "        2. $D(x^{(i)})^2 / \\sum^{m}_{j=1} D(x^{(j)})^2$의 확률로 샘플 $x^{(i)}$를 새로운 센트로이드 $c^{(i)}$로 선택\n",
    "            * $D(x^{(i)})$는 샘플 $x^{(i)}$와 이미 선택된 가장 가까운 센트로이드까지의 거리\n",
    "            * 이 확률 분포는 이미 선택한 센트로이드에서 멀리 떨어진 샘플을 다음 센트로이드로 선택할 가능성을 높임\n",
    "        3. k개의 센트로이드가 선택될 때까지 이전 단계를 반복함\n",
    "\n",
    "- *KMeans* 클래스는 기본적으로 이 초기화 방법을 사용함\n",
    "    * 원래 방식을 사용하려면? *init* 매개변수를 *\"random\"으로 지정함\n",
    "\n",
    "#### k-평균 속도 개선과 미니배치 k-평균\n",
    "- 2013년 찰스 엘칸의 논문에서 k-평균 알고리즘에 대해 또 다른 중요한 개선 제안\n",
    "    * 불필요한 거리 계산을 많이 피함으로써 알고리즘의 속도를 상당히 높일 수 있음\n",
    "    * 이를 위해 삼각 부등식을 사용 (즉 두 점 사이의 직선은 항상 짧은 거리가 됨)\n",
    "    * 그리고 샘플과 센트로이드 사이의 거리를 위한 하한선과 상한선을 유지함\n",
    "        - KMeans 클래스에서 이를 기본으로 사용 (원래 알고리즘을 사용하려면 매개변수를 *\"full\"*로 지종\n",
    "\n",
    "- 2010년 데이비드 스컬리의 논문에서 k-평균 알고리즘의 또 다른 중요한 변종 제시\n",
    "    * 전체 데이터셋을 사용해 반복하지 않고 각 반복마다 미니배치를 사용해 센트로이드를 조금씩 이동\n",
    "        - 알고리즘의 속도를 3배에서 4배 정도로 높임\n",
    "    * 또한 메모리에 들어가지 않는 대량의 데이터셋에 군집 알고리즘을 적용할 수 있음\n",
    "    * Sklearn은 *MiniBatchKMeans* 클래스에 이 알고리즘을 구현함\n",
    "        - *KMeans* 클래스처럼 이 클래스를 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44df869d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(n_clusters=5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=5)\n",
    "minibatch_kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8486c18a",
   "metadata": {},
   "source": [
    "- 데이터셋이 메모리에 들어가지 않는 경우\n",
    "    * 가장 간단한 방법은 8장의 점진적 PCA에서 했던 것처럼 *memmap* 클래스를 사용할 수 있음\n",
    "    * *MiniBatchKMeans* 클래스의 *paertial_fit()* 메서드에 한번에 하나의 미니 배치를 전달할 수 있음\n",
    "        - 그러나 초기화를 여러 번 수행하고 만들어진 결과에서 가장 좋은 것을 직접 골라야 해 해야 할 일이 \n",
    "        \n",
    "        \n",
    "- 미니배치 k-평균 알고리즘이 일반 k-평균 알고리즘보다 훨씬 빠르지만 **이너셔**는 일반적으로 조금 더 나쁨\n",
    "    * 특히 클러스터의 개수가 증가할 때 그러함\n",
    "    * [그림 9-6]에서 볼 수 있음\n",
    "        - 왼쪽 그래프 : 여러가지 클러스터 개수 k를 사용해 앞선 데이터셋에서 훈련한 미니배치 k-평균과 일반 k-평균 모델의 이너셔를 비교\n",
    "            * 두 곡선의 차이는 상당히 일정하게 유지되지만 k가 증가함에 따라 이너셔가 점점 줄어들기 때문에 이 차이가 차지하는 비율은 점점 커짐\n",
    "        - 오른쪽 그래프 : 미니배치 k-평균이 일반 k-평균보다 훨씬 빠르고 k가 증가함에 따라 더 커지는 것을 볼 수 있음\n",
    "        \n",
    "#### 최적의 클러스터 갯수 찾기\n",
    "- 일반적으로 k를 어떻게 설정할지 쉽게 알 수 없음\n",
    "    * 만약 올바르게 지정하지 않으면 결과는 매우 나쁠 수 있음\n",
    "    * [그림 9-7]은 k를 3이나 8로 지정하면 상당히 나쁜 모델이 만들어짐\n",
    "    \n",
    "- 가장 작은 이너셔를 가진 모델을 선택하면 되지 않을까?\n",
    "    * k=3 이너셔 : 653.2\n",
    "    * k=5 이너셔 : 211.6\n",
    "    * k=8 이너셔 : 119.1\n",
    "        - 이너셔는 k가 증가함에 따라 점점 작아지므로 k를 선택할 때 좋은 성능 지표가 아님\n",
    "        - 실제로 클러스터가 늘어날수록 각 샘플은 가까운 센트로이드에 더 가깝게 됨 (-> 이너셔가 더 작아짐)\n",
    "    * [그림 9-8]은 이너쇼를 k의 함수로 그래프를 그린 것\n",
    "        - k가 4까지 증가할 때 빠르게 줄어듬\n",
    "            * 그러나 k가 계속 증가하면 이너셔는 훨씬 느리게 감소함\n",
    "            * 그래프를 팔의 형태와 비슷하게 보면 k=4 지점이 엘보\n",
    "        - k에 대한 정답을 모를때는 4가 좋은 선택이 됨\n",
    "            * 이보다 작으면 변화가 심하고, 더 큰 값은 크게 도움이 되지 않기 때문\n",
    "   \n",
    "- 더 정확한 (하지만 계산 비용이 많이 드는) **실루엣 점수** 사용하여 클러스터 갯수 찾기\n",
    "    * **실루엣 점수** : 모든 샘플에 대한 **실루엣 계수**의 평균\n",
    "        - 샘플의 실루엣 계수 : $(b-a) / max(a, b)$로 계산\n",
    "            * $a$ : 동일한 클러스터에 있는 다른 샘플까지 평균 거리 (클러스터 내부의 평균 거리)\n",
    "            * $b$ : 가장 가까운 클러스터까지의 평균 거리 (가장 가까운 클러스터의 샘플까지의 평균 거리)\n",
    "                - 샘플과 가장 가까운 클러스터는 자신이 속한 클러스터를 제외하고 b가 최소인 클러스터\n",
    "        - 실루엣 계수는 -1에서 +1까지 바뀔 수 있음\n",
    "            * +1에 가까우면 자신의 클러스터 안에 잘 속해있고 다른 클러스터와는 멀리 떨어져 있다는 뜻\n",
    "            * 0에 가까우면 클러스터 경계에 위치한다는 의미\n",
    "            * -1에 가까우면 이 샘플이 잘못된 클러스터에 할당되었다는 의미\n",
    "    * 계산하려면 Sklearn의 *silhouette_score()* 함수 사용\n",
    "        - 데이터셋에 있는 모든 샘플과 할당된 레이블 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6829efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.655517642572828"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_score(X, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8db4c2",
   "metadata": {},
   "source": [
    "- 클러스터의 개수를 달리하여 실루엣 점수 비교하기 (그림 9-9)\n",
    "    * 이전보다 훨씬 더 많은 정보를 주고 있음\n",
    "        - k=4가 좋은 선택이지만 k=5도 꽤 좋다는 사실을 잘 보여줌 (k=6이나 7보다 훨씬 좋음)\n",
    "            * 이너셔를 비교했을 때는 드러나지 않았음\n",
    "\n",
    "- 모든 샘플의 실루엣 계수를 할당한 클러스터와 계숫값으로 정렬하여 그리면 더 많은 정보가 있는 그래프를 얻을 수 있음\n",
    "    * 이를 **실루엣 다이어그램**이라고 함 (그림 9-10)\n",
    "        - 클러스터마다 **칼 모양**의 그래프가 그려짐\n",
    "            * 높이 : 클러스터가 포함하고 있는 샘플의 개수 의미\n",
    "            * 너비 : 클러스터에 포함된 샘플의 정렬된 실루엣 계수를 나타냄 (넓을수록 좋음)\n",
    "\n",
    "### 9.1.3 군집을 사용한 이미지 분할\n",
    "- **이미지 분할**은 이미지를 세그먼트 여러 개로 분할하는 작업\n",
    "    * **시맨틱 분할**에서는 동일한 종류의 물체에 속한 모든 픽셀은 같은 세그먼트에 할당됨\n",
    "        - ex. 자율 주행 자동차의 비전 시스템에서 보행자 이미지를 구성하는 모든 픽셀은 '보행자' 세그먼트에 할당\n",
    "            * 이 경우 각 보행자는 다른 세그먼트가 될 수 있음 (이런 경우를 '인스턴스 분할' 이라고 부름)\n",
    "- 시맨틱 또는 인스턴스 분할에서 최고 수준의 성능을 내려면 합성곱 신경망 (14장)을 사용한 복잡한 모델을 사용해야 함\n",
    "    * 여기서는 훨씬 더 쉬운 작업인 **색상 분할**을 수행함\n",
    "       - 동일한 색상을 가진 픽셀을 같은 세그먼트에 할당할 것임\n",
    "    * 어떤 애플리케이션에서는 이 정도로 충분할 수 있음\n",
    "        - ex. 인공지능 사진을 분석하여 한 지역의 전체 산림 면적이 얼마나 되는지 측정하는 경우\n",
    "\n",
    "\n",
    "- matplotlib의 *imread()* 함수를 이용해 이미지를 읽어오기 (그림 9-12의 왼쪽 위 이미지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a777f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533, 800, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.image import imread\n",
    "import os\n",
    "image = imread(os.path.join(\"images\", \"unsupervised_learning\", \"ladybug.png\"))\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a12a74",
   "metadata": {},
   "source": [
    "- 이 이미지는 3D 배열로 표현됨\n",
    "    * 1차원 : 높이\n",
    "    * 2차원 : 너비\n",
    "    * 3차원 : 컬러 채널 갯수\n",
    "        - 빨강, 초록, 파랑 (RGB) 채널\n",
    "        - 각 픽셀에 대해 빨강, 초록, 파랑의 강도를 담은 3D 벡터 존재\n",
    "        - 0.0과 1.0 사이의 값을 가짐 (*imageio.imread()*를 사용하면 0~255)\n",
    "        - 어떤 이미지는 더 적은 채널을 가지기도 함 (흑백 이미지 (1채널))\n",
    "        - 혹은 더 많은 채널 (투명도를 위한 알파 채널 or 위성 이미지)을 가지기도 함\n",
    "            * 위성 이미지는 종종 여러 전자기파에 대한 채널을 포함 (적외선 등)\n",
    "            \n",
    "- 이 배열을 RGB 색상의 긴 리스트로 변환한 다음 k-평균을 사용해 이 색상을 클러스터로 모음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd61efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = image.reshape(-1, 3)\n",
    "kmeans = KMeans(n_clusters=8).fit(X)\n",
    "segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
    "segmented_img = segmented_img.reshape(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdbc092",
   "metadata": {},
   "source": [
    "- 예 : 모든 초록색을 하나의 컬러 클러스터로 만들 수 있음\n",
    "    * 그 다음 각 색상에 대해 그 픽셀의 컬러 클라스터의 평균 클러스터를 찾음\n",
    "        - ex. 모든 초록색은 모두 밝은 초록색으로 바뀔 수 있음 (평균 색이 밝은 초록색이라고 가정)\n",
    "    * 마지막으로 긴 색상 리스트를 원본 이미지와 동일한 크기로 변경\n",
    "\n",
    "- 이 과정을 통해 [그림 9-12]의 오른쪽 위에 보이는 이미지를 출력할 수 있음\n",
    "    * 그림처럼 클러스터 개수를 여러 개로 바꿔 테스트할 수 있음\n",
    "        - 클러스터 개수 < 8 - 무당벌레의 빨간색이 독자적인 클러스터를 만들지 못하고 주위 색에 합쳐짐\n",
    "            * k-평균이 비슷한 크기의 클러스터를 만드는 경향이 있기 때문\n",
    "        - 무당벌레는 이미지의 나머지 부분보다 훨씬 작기 때문에 화려한 색을 가지고 있더라도 k-평균이 무당벌레를 하나의 클러스터로 만들지 못함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ad131",
   "metadata": {},
   "source": [
    "### 9.1.4 군집을 사용한 전처리\n",
    "- 군집은 **지도 학습 알고리즘**을 적용하기 전에 **전처리** 단계로 이용할 수 있음\n",
    "    * 차원 축소에 군집을 사용하는 예를 다뤄보기 위해 숫자 데이터셋 사용\n",
    "        - MNIST와 비슷한 데이터셋으로 0부터 9까지 숫자를 나타내는 8x8 크기 흑백 이미지 1,797개를 담고 있음\n",
    "\n",
    "- 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e3e79dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688888888888889"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 불러오기\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_digits, y_digits = load_digits(return_X_y=True)\n",
    "\n",
    "# 훈련 세트와 테스트 세트로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits, random_state=42)\n",
    "\n",
    "# 로지스틱 회귀 모델 훈련\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 세트에서 정확도 평가\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a87f4a",
   "metadata": {},
   "source": [
    "- 기준값으로 96.9% 정확도를 얻음\n",
    "- k-평균을 전처리 단계로 사용하여 더 좋아지는지 확인\n",
    "    * 파이프라인을 만들어 훈련 세트를 50개의 클러스터로 모으고, 이미지를 50개 클러스터까지의 거리로 바꿈\n",
    "    * 그 다음 로지스틱 회귀 모델을 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49c49e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"kmeans\", KMeans(n_clusters=50)),\n",
    "    (\"log_reg\", LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 분류 파이프라인 평가\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b20493",
   "metadata": {},
   "source": [
    "- 약 30%까지 오차율 감소 확인\n",
    "\n",
    "- 군집이 데이터셋의 차원을 (64에서 50으로) 감소시켰지만 성능 향상은 대부분 변환된 데이터셋이 원본 데이터셋보다 선혈적으로 잘 구분될 수 있기 때문에 이뤄짐\n",
    "    * 따라서 로지스틱 회귀를 사용하기 더 좋음\n",
    "\n",
    "- 클러스터 개수 k를 임의로 정함\n",
    "    * 이보다 더 좋은 결과를 낼 수 있음\n",
    "    * k-평균이 분류 파이프라인의 하나의 전처리 단계이기 때문에 이전보다 좋은 k값을 찾는 일이 더 쉬움\n",
    "        - 실루엣 분석이나 이너셔가 감소되는지 확인할 필요 없음\n",
    "    * 가장 좋은 k값은 교차검증에서 가장 좋은 분류 성능을 내는 값임\n",
    "        - *GridSearchCV*를 사용하여 최적의 클러스터 개수를 찾을 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eee9a0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 98 candidates, totalling 294 fits\n",
      "[CV] END ...............................kmeans__n_clusters=2; total time=   0.1s\n",
      "[CV] END ...............................kmeans__n_clusters=2; total time=   0.1s\n",
      "[CV] END ...............................kmeans__n_clusters=2; total time=   0.1s\n",
      "[CV] END ...............................kmeans__n_clusters=3; total time=   0.1s\n",
      "[CV] END ...............................kmeans__n_clusters=3; total time=   0.1s\n",
      "[CV] END ...............................kmeans__n_clusters=3; total time=   0.1s\n",
      "[CV] END ...............................kmeans__n_clusters=4; total time=   0.2s\n",
      "[CV] END ...............................kmeans__n_clusters=4; total time=   0.1s\n",
      "[CV] END ...............................kmeans__n_clusters=4; total time=   0.1s\n",
      "[CV] END ...............................kmeans__n_clusters=5; total time=   0.2s\n",
      "[CV] END ...............................kmeans__n_clusters=5; total time=   0.2s\n",
      "[CV] END ...............................kmeans__n_clusters=5; total time=   0.1s\n",
      "[CV] END ...............................kmeans__n_clusters=6; total time=   0.2s\n",
      "[CV] END ...............................kmeans__n_clusters=6; total time=   0.2s\n",
      "[CV] END ...............................kmeans__n_clusters=6; total time=   0.2s\n",
      "[CV] END ...............................kmeans__n_clusters=7; total time=   0.2s\n",
      "[CV] END ...............................kmeans__n_clusters=7; total time=   0.2s\n",
      "[CV] END ...............................kmeans__n_clusters=7; total time=   0.2s\n",
      "[CV] END ...............................kmeans__n_clusters=8; total time=   0.3s\n",
      "[CV] END ...............................kmeans__n_clusters=8; total time=   0.2s\n",
      "[CV] END ...............................kmeans__n_clusters=8; total time=   0.3s\n",
      "[CV] END ...............................kmeans__n_clusters=9; total time=   0.3s\n",
      "[CV] END ...............................kmeans__n_clusters=9; total time=   0.3s\n",
      "[CV] END ...............................kmeans__n_clusters=9; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=10; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=10; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=10; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=11; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=11; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=11; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=12; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=12; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=12; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=13; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=13; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=13; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=14; total time=   1.0s\n",
      "[CV] END ..............................kmeans__n_clusters=14; total time=   1.0s\n",
      "[CV] END ..............................kmeans__n_clusters=14; total time=   1.0s\n",
      "[CV] END ..............................kmeans__n_clusters=15; total time=   1.3s\n",
      "[CV] END ..............................kmeans__n_clusters=15; total time=   1.1s\n",
      "[CV] END ..............................kmeans__n_clusters=15; total time=   1.2s\n",
      "[CV] END ..............................kmeans__n_clusters=16; total time=   1.3s\n",
      "[CV] END ..............................kmeans__n_clusters=16; total time=   1.2s\n",
      "[CV] END ..............................kmeans__n_clusters=16; total time=   1.3s\n",
      "[CV] END ..............................kmeans__n_clusters=17; total time=   1.5s\n",
      "[CV] END ..............................kmeans__n_clusters=17; total time=   1.5s\n",
      "[CV] END ..............................kmeans__n_clusters=17; total time=   1.4s\n",
      "[CV] END ..............................kmeans__n_clusters=18; total time=   1.6s\n",
      "[CV] END ..............................kmeans__n_clusters=18; total time=   1.5s\n",
      "[CV] END ..............................kmeans__n_clusters=18; total time=   1.5s\n",
      "[CV] END ..............................kmeans__n_clusters=19; total time=   1.7s\n",
      "[CV] END ..............................kmeans__n_clusters=19; total time=   1.6s\n",
      "[CV] END ..............................kmeans__n_clusters=19; total time=   1.7s\n",
      "[CV] END ..............................kmeans__n_clusters=20; total time=   2.3s\n",
      "[CV] END ..............................kmeans__n_clusters=20; total time=   2.0s\n",
      "[CV] END ..............................kmeans__n_clusters=20; total time=   2.2s\n",
      "[CV] END ..............................kmeans__n_clusters=21; total time=   2.3s\n",
      "[CV] END ..............................kmeans__n_clusters=21; total time=   2.2s\n",
      "[CV] END ..............................kmeans__n_clusters=21; total time=   2.3s\n",
      "[CV] END ..............................kmeans__n_clusters=22; total time=   2.1s\n",
      "[CV] END ..............................kmeans__n_clusters=22; total time=   1.8s\n",
      "[CV] END ..............................kmeans__n_clusters=22; total time=   1.9s\n",
      "[CV] END ..............................kmeans__n_clusters=23; total time=   2.0s\n",
      "[CV] END ..............................kmeans__n_clusters=23; total time=   2.0s\n",
      "[CV] END ..............................kmeans__n_clusters=23; total time=   1.9s\n",
      "[CV] END ..............................kmeans__n_clusters=24; total time=   2.1s\n",
      "[CV] END ..............................kmeans__n_clusters=24; total time=   2.0s\n",
      "[CV] END ..............................kmeans__n_clusters=24; total time=   2.3s\n",
      "[CV] END ..............................kmeans__n_clusters=25; total time=   2.8s\n",
      "[CV] END ..............................kmeans__n_clusters=25; total time=   2.8s\n",
      "[CV] END ..............................kmeans__n_clusters=25; total time=   3.0s\n",
      "[CV] END ..............................kmeans__n_clusters=26; total time=   3.0s\n",
      "[CV] END ..............................kmeans__n_clusters=26; total time=   2.9s\n",
      "[CV] END ..............................kmeans__n_clusters=26; total time=   2.6s\n",
      "[CV] END ..............................kmeans__n_clusters=27; total time=   2.7s\n",
      "[CV] END ..............................kmeans__n_clusters=27; total time=   2.5s\n",
      "[CV] END ..............................kmeans__n_clusters=27; total time=   2.9s\n",
      "[CV] END ..............................kmeans__n_clusters=28; total time=   2.7s\n",
      "[CV] END ..............................kmeans__n_clusters=28; total time=   2.8s\n",
      "[CV] END ..............................kmeans__n_clusters=28; total time=   2.7s\n",
      "[CV] END ..............................kmeans__n_clusters=29; total time=   2.9s\n",
      "[CV] END ..............................kmeans__n_clusters=29; total time=   2.7s\n",
      "[CV] END ..............................kmeans__n_clusters=29; total time=   2.7s\n",
      "[CV] END ..............................kmeans__n_clusters=30; total time=   2.5s\n",
      "[CV] END ..............................kmeans__n_clusters=30; total time=   2.3s\n",
      "[CV] END ..............................kmeans__n_clusters=30; total time=   2.4s\n",
      "[CV] END ..............................kmeans__n_clusters=31; total time=   3.0s\n",
      "[CV] END ..............................kmeans__n_clusters=31; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=31; total time=   3.0s\n",
      "[CV] END ..............................kmeans__n_clusters=32; total time=   3.1s\n",
      "[CV] END ..............................kmeans__n_clusters=32; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=32; total time=   2.9s\n",
      "[CV] END ..............................kmeans__n_clusters=33; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=33; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=33; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=34; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=34; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=34; total time=   2.9s\n",
      "[CV] END ..............................kmeans__n_clusters=35; total time=   2.8s\n",
      "[CV] END ..............................kmeans__n_clusters=35; total time=   3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................kmeans__n_clusters=35; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=36; total time=   2.9s\n",
      "[CV] END ..............................kmeans__n_clusters=36; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=36; total time=   3.0s\n",
      "[CV] END ..............................kmeans__n_clusters=37; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=37; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=37; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=38; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=38; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=38; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=39; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=39; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=39; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=40; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=40; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=40; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=41; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=41; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=41; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=42; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=42; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=42; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=43; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=43; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=43; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=44; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=44; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=44; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=45; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=45; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=45; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=46; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=46; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=46; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=47; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=47; total time=   3.1s\n",
      "[CV] END ..............................kmeans__n_clusters=47; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=48; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=48; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=48; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=49; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=49; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=49; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=50; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=50; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=50; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=51; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=51; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=51; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=52; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=52; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=52; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=53; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=53; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=53; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=54; total time=   3.0s\n",
      "[CV] END ..............................kmeans__n_clusters=54; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=54; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=55; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=55; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=55; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=56; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=56; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=56; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=57; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=57; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=57; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=58; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=58; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=58; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=59; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=59; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=59; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=60; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=60; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=60; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=61; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=61; total time=   4.4s\n",
      "[CV] END ..............................kmeans__n_clusters=61; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=62; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=62; total time=   4.5s\n",
      "[CV] END ..............................kmeans__n_clusters=62; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=63; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=63; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=63; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=64; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=64; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=64; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=65; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=65; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=65; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=66; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=66; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=66; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=67; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=67; total time=   4.2s\n",
      "[CV] END ..............................kmeans__n_clusters=67; total time=   4.7s\n",
      "[CV] END ..............................kmeans__n_clusters=68; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=68; total time=   4.9s\n",
      "[CV] END ..............................kmeans__n_clusters=68; total time=   5.1s\n",
      "[CV] END ..............................kmeans__n_clusters=69; total time=   5.0s\n",
      "[CV] END ..............................kmeans__n_clusters=69; total time=   5.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................kmeans__n_clusters=69; total time=   4.8s\n",
      "[CV] END ..............................kmeans__n_clusters=70; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=70; total time=   4.5s\n",
      "[CV] END ..............................kmeans__n_clusters=70; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=71; total time=   5.7s\n",
      "[CV] END ..............................kmeans__n_clusters=71; total time=   6.3s\n",
      "[CV] END ..............................kmeans__n_clusters=71; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=72; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=72; total time=   4.2s\n",
      "[CV] END ..............................kmeans__n_clusters=72; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=73; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=73; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=73; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=74; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=74; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=74; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=75; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=75; total time=   4.2s\n",
      "[CV] END ..............................kmeans__n_clusters=75; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=76; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=76; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=76; total time=   3.1s\n",
      "[CV] END ..............................kmeans__n_clusters=77; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=77; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=77; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=78; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=78; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=78; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=79; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=79; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=79; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=80; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=80; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=80; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=81; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=81; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=81; total time=   3.1s\n",
      "[CV] END ..............................kmeans__n_clusters=82; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=82; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=82; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=83; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=83; total time=   4.2s\n",
      "[CV] END ..............................kmeans__n_clusters=83; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=84; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=84; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=84; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=85; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=85; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=85; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=86; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=86; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=86; total time=   3.1s\n",
      "[CV] END ..............................kmeans__n_clusters=87; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=87; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=87; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=88; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=88; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=88; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=89; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=89; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=89; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=90; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=90; total time=   4.2s\n",
      "[CV] END ..............................kmeans__n_clusters=90; total time=   4.2s\n",
      "[CV] END ..............................kmeans__n_clusters=91; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=91; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=91; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=92; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=92; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=92; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=93; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=93; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=93; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=94; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=94; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=94; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=95; total time=   4.2s\n",
      "[CV] END ..............................kmeans__n_clusters=95; total time=   4.5s\n",
      "[CV] END ..............................kmeans__n_clusters=95; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=96; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=96; total time=   4.4s\n",
      "[CV] END ..............................kmeans__n_clusters=96; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=97; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=97; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=97; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=98; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=98; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=98; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=99; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=99; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=99; total time=   4.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'kmeans__n_clusters': 82}, 0.9822222222222222)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = dict(kmeans__n_clusters=range(2, 100))\n",
    "grid_clf = GridSearchCV(pipeline, param_grid, cv=3, verbose=2)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "\n",
    "# 최선의 k값과 이때 파이프라인 성능 확인\n",
    "grid_clf.best_params_, grid_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737f48a",
   "metadata": {},
   "source": [
    "- k=99개의 클러스터를 사용할 때 정확도가 크게 향삼됨\n",
    "    * 테스트 세트에서 98.22%를 달성\n",
    "    * 99가 탐색 범위에서 가장 큰 값이므로 더 높은 k값을 탐색해볼 여지도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b463243",
   "metadata": {},
   "source": [
    "### 9.1.5 군집을 사용한 준지도 학습\n",
    "- 군집을 사용하는 또 다른 사례 -> **준지도 학습**\n",
    "    * 레이블이 없는 데이터가 많고 레이블이 있는 데이터는 적을 때 사용\n",
    "\n",
    "- 숫자 데이터셋에서 레이블된 50개 샘플에 로지스틱 회귀 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d2824c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aftermoon/opt/anaconda3/envs/HandsOn-ML/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8266666666666667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labeled = 50\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train[:n_labeled], y_train[:n_labeled])\n",
    "\n",
    "# 성능 확인\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e8c8a7",
   "metadata": {},
   "source": [
    "- 정확도가 82.6% -> 전체 데이터셋을 사용했을 때보다 낮은 정확도가 나오게 됨\n",
    "- 어떻게 개선할 수 있는가?\n",
    "    1. 훈련 세트를 50개의 클러스터로 모음\n",
    "    2. 그 다음 각 클러스터에서 센트로이드에 가장 가까운 이미지를 찾음\n",
    "        - 이런 이미지들을 **대표 이미지** 라고 부름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1e35a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "X_digits_dist = kmeans.fit_transform(X_train)\n",
    "representative_digit_idx = np.argmin(X_digits_dist, axis=0)\n",
    "X_representative_digits = X_train[representative_digit_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4aac6044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 50 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 출력 (from Github)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "for index, X_representative_digit in enumerate(X_representative_digits):\n",
    "    plt.subplot(k // 10, 10, index + 1)\n",
    "    plt.imshow(X_representative_digit.reshape(8, 8), cmap=\"binary\", interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f32e9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수동으로 레이블 할당\n",
    "y_representative_digits = np.array([4, 8, 0, 6, 8, 3, 7, 7, 9, 2, \n",
    "                                    5, 5, 8, 5, 2, 1, 2, 9, 6, 1, \n",
    "                                    1, 6, 9, 0, 8, 3, 0, 7, 4, 1, \n",
    "                                    6, 5, 2, 4, 1, 8, 6, 3, 9, 2, \n",
    "                                    4, 2, 9, 4, 7, 6, 2, 3, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b55db58",
   "metadata": {},
   "source": [
    "- 레이블된 50개 샘플로 이루어진 데이터셋이 준비됨\n",
    "    * 하지만 무작위로 고른 샘플이 아닌 각 클러스터를 대표하는 이미지\n",
    "\n",
    "- 성능이 조금이라도 높아졌는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49267bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9222222222222223"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_representative_digits, y_representative_digits)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fdce4b",
   "metadata": {},
   "source": [
    "- 성능이 82.6%에서 92.2%로 높게 상승\n",
    "    * 샘플에 레이블을 부여하는 것은 비용이 많이 들고 어려움\n",
    "        - 특히 전문가가 수동으로 처리해야할 때 그러함\n",
    "    * 따라서 무자구이 샘플 대신 대표 샘플에 레이블을 할당하는 것이 좋은 방법\n",
    "\n",
    "- 여기서 한 단계 더 나아가 이 레이블을 동일한 클러스터에 있는 모든 샘플로 전파하는 **레이블 전파**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72189a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_propagated = np.empty(len(X_train), dtype=np.int32)\n",
    "for i in range(k):\n",
    "    y_train_propagated[kmeans.labels_==i] = y_representative_digits[i]\n",
    "    \n",
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_train, y_train_propagated)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c2c87b",
   "metadata": {},
   "source": [
    "- 성능은 올라갔으나 놀라운 정도는 아님\n",
    "    * 각 대표 샘플의 레이블을 동일한 클러스터의 모든 샘플에 전파한 것이 문제가 됨\n",
    "        - 클러스터 경계에 가깝게 위치한 샘플이 포함되어 있어 레이블이 잘못 부여되었을 것임\n",
    " \n",
    "- 센트로이드와 가까운 샘플의 20%에만 레이블을 전파해보고 어떻게 되는지 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "123d9aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentile_closest = 20\n",
    "X_cluster_dist = X_digits_dist[np.arange(len(X_train,)), kmeans.labels_]\n",
    "\n",
    "for i in range(k):\n",
    "    in_cluster = (kmeans.labels_ == i)\n",
    "    cluster_dist = X_cluster_dist[in_cluster]\n",
    "    cutoff_distance = np.percentile(cluster_dist, percentile_closest)\n",
    "    above_cutoff = (X_cluster_dist > cutoff_distance)\n",
    "    X_cluster_dist[in_cluster & above_cutoff] = -1\n",
    "    \n",
    "partially_propagated = (X_cluster_dist != -1)\n",
    "X_train_partially_propagated = X_train[partially_propagated]\n",
    "y_train_partially_propagated = y_train_propagated[partially_propagated]\n",
    "\n",
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_train_partially_propagated, y_train_partially_propagated)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08731cd",
   "metadata": {},
   "source": [
    "- 레이블된 샘플 50개만으로 94.0%의 정확도를 얻음\n",
    "    * 레이블이 있는 전체 데이터셋에서 훈련한 로지스틱 회귀 성능 (96.9%)에 매우 가까움\n",
    "- 성능이 좋은 이유 : 전파된 레이블이 실제로 매우 좋기 때문\n",
    "    * 다음 코드에서 볼 수 있듯 99% 실제 데이터와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a5b4ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9896907216494846"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train_partially_propagated == y_train[partially_propagated])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e889efe7",
   "metadata": {},
   "source": [
    "##### 능동 학습\n",
    "- 모델과 훈련 세트를 지속적으로 향상하기 위해 다음 단계로 **능동 학습**을 몇 번 반복할 수 있음\n",
    "    * 전문가와 학습 알고리즘이 상호작용하여 알고리즘이 요청할 때 특정 샘플의 레이블을 제공\n",
    "- 능동 학습에는 여러 다른 학습 전략이 존재하지만, 가장 널리 사용되는 것 중 하나는 **불확실성 샘플링**\n",
    "    * 작동 방식\n",
    "        1. 지금까지 수집된 레이블된 샘플에서 모델을 훈련함\n",
    "            * 이 모델을 사용해 레이블되지 않은 모든 샘플에 대한 예측을 만듬\n",
    "        2. 모델이 가장 불확실하게 예측한 샘플 (즉 추정 확률이 낮은 샘플)을 전문가에게 보내 레이블을 붙임\n",
    "        3. 레이블을 부여하는 노력만큼의 성능이 향상되지 않을 때까지 이를 반복\n",
    "- 다른 방법\n",
    "    * 모델을 가장 크게 바꾸는 샘플이나 모델의 검증 점수를 가장 크게 떨어뜨리는 샘플, 여러 개의 모델 (SVM, 랜덤 포레스트 등)이 동일한 예측을 내지 않는 샘플에 대해 레이블을 요청"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6107539a",
   "metadata": {},
   "source": [
    "### 9.1.6 DBSCAN\n",
    "- 밀집된 연속적 지역을 클러스터로 정의\n",
    "    * 알고리즘이 각 샘플에서 작은 거리인 $\\epsilon$ (입실론) 내에 샘플이 몇 개 놓여있는지 셈\n",
    "        - 이 지역을 샘플의 **$\\epsilon$-이웃**이라고 부름\n",
    "    * (자기 자신을 포함해) $\\epsilon$-이웃 내에 적어도 *min_samples*개 샘플이 있다면 이를 **핵심 샘플**로 간주\n",
    "        - 즉 핵심 샘플 -> 밀집된 지역에 있는 샘플\n",
    "    * 핵심 샘플의 이웃에 있는 모든 새믈은 동일한 클러스터에 속함\n",
    "        - 이웃에는 다른 핵심 샘플이 포함될 수 있음\n",
    "        - 따라서 핵심 샘플의 이웃의 이웃은 계속해서 하나의 클러스터를 형성함\n",
    "    * 핵심 샘플이 아니고 이웃도 아닌 샘플은 이상치로 판단함\n",
    "\n",
    "- 이 알고리즘은 모든 클러스터가 충분히 밀집되어 있고 밀집되지 않는 지역과 잘 구분될 때 좋은 성능을 냄\n",
    "    * Sklearn에 있는 *DBSCAN* 클래스는 사용법이 간단함\n",
    "\n",
    "- 반달 모양 데이터셋에서 테스트해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a1db1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(eps=0.05)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.05)\n",
    "dbscan = DBSCAN(eps=0.05, min_samples=5)\n",
    "dbscan.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43e00929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  1,  0,  0,  1,  2,  0,  0,  1,  3, -1,  3,  3, -1,  1,\n",
       "        0,  0,  0, -1,  1,  4,  1,  1,  0,  1,  1,  1,  3,  1, -1,  1, -1,\n",
       "        1,  0,  1,  1,  1,  1,  1,  0,  1, -1,  1,  1,  1,  1,  1,  2,  1,\n",
       "        0,  0, -1, -1,  1,  1,  3,  0,  1,  0,  1,  3, -1,  1,  0,  4,  4,\n",
       "        1, -1,  0,  3,  3,  1,  3,  1,  1,  0,  1,  1,  1,  3,  1,  0,  1,\n",
       "        2,  0,  1,  1,  1,  0,  1,  0,  1,  1,  4,  1,  7,  0,  1,  1,  0,\n",
       "        2,  1,  1,  0,  1,  3,  1,  0,  0,  0,  0,  1,  2,  1,  1,  3,  1,\n",
       "        0,  1,  0,  5,  1,  3,  0,  3,  2,  1,  1,  1,  1,  2,  3,  3,  0,\n",
       "        3,  1, -1,  1,  0,  1,  0,  0,  3,  1,  3,  3,  3,  2, -1,  1,  1,\n",
       "        0,  0,  1,  0,  1,  0,  0,  3,  1,  0,  3,  1,  0,  0,  1,  2, -1,\n",
       "       -1,  1,  1,  0,  2,  1,  3,  0,  0,  3,  1,  1,  1, -1,  1,  3,  1,\n",
       "        0,  1,  1,  0,  0,  1,  1,  3,  3,  1,  5,  0,  3,  1, -1,  5,  3,\n",
       "        0,  0,  1,  1,  1,  1,  0,  0,  0,  1,  0,  0,  1,  0,  0,  1, -1,\n",
       "        0,  3,  1,  1, -1,  1,  0,  0,  0,  0,  0,  1,  1,  0,  1,  1,  1,\n",
       "        1,  3,  1, -1,  0,  1, -1,  1,  0,  0,  3,  1,  0,  1,  1,  1,  2,\n",
       "        1,  0,  1, -1,  3,  6,  3, -1,  1,  0,  1,  1,  1, -1,  1,  0,  0,\n",
       "        4, -1, -1,  0,  0,  3,  1,  1, -1,  1,  1,  1,  1,  0,  6,  0,  0,\n",
       "       -1,  2,  1,  3,  3,  1,  1,  1,  1, -1,  1,  1,  2,  1,  0,  1,  0,\n",
       "       -1,  1,  0,  3,  2,  3,  0,  0,  1, -1,  0,  1,  1,  1,  1,  1,  1,\n",
       "       -1,  3,  0,  1,  1,  1,  1, -1,  1,  2,  1,  1,  1, -1,  1,  3,  1,\n",
       "        1,  1,  3,  1,  0,  3,  0,  2, -1,  3,  0,  1,  4,  1,  3,  3,  0,\n",
       "        0,  1,  3,  1,  1,  0, -1,  0, -1,  0,  0,  1,  0,  1,  3,  2,  1,\n",
       "        1,  3,  0,  1,  1,  1,  3,  0,  1,  0,  2,  3,  1,  0,  3,  0,  0,\n",
       "        0,  0,  3,  1,  3,  3,  2,  0,  1,  3,  0,  0,  0,  3,  3, -1,  1,\n",
       "        3,  3,  1,  1,  0,  0,  1,  1,  1,  1,  0,  0, -1,  1,  1,  1,  0,\n",
       "        0,  0,  1,  6,  1,  0,  3,  3,  1,  1,  1,  1, -1,  0,  1,  1,  1,\n",
       "       -1,  1,  1,  0,  3,  3,  1,  1, -1,  1,  1,  0,  1,  1,  3,  1,  1,\n",
       "        0,  1,  3,  3,  0,  0,  0,  3,  1,  1,  0,  3,  1,  1,  3,  2,  0,\n",
       "        2,  2,  0,  3,  1,  1,  0,  1,  3,  1,  0,  1,  1,  1,  0,  1,  1,\n",
       "        0,  2,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  6,  2,  0,  1,\n",
       "        1,  3,  3,  0,  3,  1,  0, -1,  0,  1,  3,  1,  0,  0,  3,  1,  1,\n",
       "        0,  4,  0,  1,  1,  1,  1,  1,  1,  1,  0,  1,  3,  1,  1, -1,  0,\n",
       "        1,  1,  1,  2,  1, -1,  1,  3,  3,  1,  1,  1,  1,  3,  1,  0,  1,\n",
       "        3,  3,  1,  3,  2,  1,  1,  1,  0,  0,  1,  1, -1,  0,  0,  1, -1,\n",
       "        0,  3,  0,  1, -1, -1,  2,  0,  3,  0,  1,  0,  0,  0,  1,  0,  1,\n",
       "        3,  1,  1, -1,  1,  2,  5,  1,  7,  3,  3,  0,  3,  3,  1,  2,  2,\n",
       "        1,  1,  3,  1,  3,  2,  0,  3,  1,  1,  1,  6,  1,  1,  0,  1,  0,\n",
       "        1,  2,  1,  5,  0,  3,  1,  3,  1,  1,  0,  2,  3,  1,  0,  1,  3,\n",
       "        1,  0,  3,  4,  2,  1,  3,  2,  0,  1,  0, -1,  0,  3,  0, -1, -1,\n",
       "        1,  1,  2, -1,  1,  1,  1,  2, -1,  1,  0,  1,  1,  1, -1,  1,  1,\n",
       "        1,  1,  3,  0, -1,  0,  1,  1,  3, -1,  3,  2,  1,  1,  0,  6,  0,\n",
       "        1,  0,  1,  3,  3, -1,  0,  1, -1,  1,  3,  0,  1,  0,  0,  0,  1,\n",
       "        0,  1,  3,  1,  1,  1,  1,  1,  0,  3,  1,  0,  3,  3,  1,  0,  2,\n",
       "        1,  0,  0,  1,  1,  3,  1,  0,  1,  3,  0,  0,  3, -1,  0,  1,  0,\n",
       "        0,  1,  1,  1,  1,  1,  3,  1,  1,  1,  0,  1,  1,  1,  0,  1,  1,\n",
       "        0,  1, -1,  1,  1,  2,  3,  3, -1,  3,  1,  1,  3,  0,  1,  1,  1,\n",
       "        0,  1,  3,  1,  1,  0, -1,  0,  5,  2,  4,  1,  1,  1,  1,  3,  3,\n",
       "        0,  1,  1,  1, -1, -1,  0,  1,  1,  0,  3,  1,  1,  1,  1,  0, -1,\n",
       "        1,  1,  0,  1, -1,  1,  1,  1,  0,  1,  1,  1,  1,  0,  1,  1,  1,\n",
       "        1,  0,  1,  1,  1,  1,  0,  3,  0,  2,  0, -1,  1,  1,  0,  0,  0,\n",
       "       -1,  0,  3, -1,  1,  2,  0,  3,  3,  1,  3,  1, -1,  1,  1,  0,  3,\n",
       "        1,  1,  5,  1,  1,  0,  1,  1,  1,  1,  1,  3,  2,  0,  0,  1,  0,\n",
       "        1,  0,  3,  1,  1,  1,  3,  0,  3,  2,  1,  1,  1,  0,  0,  2,  0,\n",
       "       -1,  1,  0,  0,  1,  0,  0,  0, -1,  3,  3,  1,  3,  0,  3,  1,  3,\n",
       "        0,  1,  3,  2,  1,  0,  1,  1,  0,  0, -1,  0,  1,  1,  1,  1,  1,\n",
       "        1, -1,  1,  1,  1,  3,  0,  3,  1,  1,  1,  1,  1,  3,  0,  0,  3,\n",
       "        1,  3,  3,  1,  0,  1,  0,  0,  3,  1,  7,  1,  1, -1,  1,  0,  3,\n",
       "        0,  0,  3,  0,  1,  1,  1,  1,  2,  1,  4,  1,  4,  1,  1,  3,  1,\n",
       "        1,  1,  3,  1,  3,  3,  6,  3,  1,  3,  1,  0, -1,  3])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 샘플의 레이블은 인스턴스 변수 labels_에 저장되어 있음\n",
    "dbscan.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05df28f",
   "metadata": {},
   "source": [
    "- 일부 샘플의 클러스터 인덱스는 -1\n",
    "    * 알고리즘이 이 샘플을 이상치로 판단했다는 의미\n",
    "    * 핵심 샘플의 인덱스는 인스턴스 변수 *core_sample_indices_*에서 확인할 수 있음\n",
    "    * 핵심 샘플 자체는 인스턴스 변수 *components_*에 저장되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b14dcca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dbscan.core_sample_indices_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d945a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.85497292, -0.03728811],\n",
       "       [-0.96855909,  0.45038058],\n",
       "       [ 2.00542971,  0.41302753],\n",
       "       ...,\n",
       "       [ 0.95205999,  0.26788396],\n",
       "       [ 1.29083913, -0.45525327],\n",
       "       [ 0.47756861, -0.35646177]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881802e3",
   "metadata": {},
   "source": [
    "- 이 군집 결과가 [그림 9-14] 왼쪽 그래프에 있음\n",
    "    * 그림에서 볼 수 있듯 클러스터를 7개 만들었으며 많는 샘플을 이상치 (X)로 판단\n",
    "    * 다행히 *eps*를 0.2로 증가해 샘플의 이웃 범위를 넓히면 오른쪽 그래프처럼 완벽한 군집을 이룸\n",
    "        - 이 모델로 계속 진행\n",
    "        \n",
    "\n",
    "- *DBSCAN* 클래스는 *predict()* 메서드를 제공하지 않고 *fit_predict()* 메서드를 제공\n",
    "    - 새로운 샘플에 대해 클러스터를 예측할 수 없음을 의미\n",
    "        * 이러한 구현 결정은 다른 분류 알고리즘이 이런 작업을 더 잘 수행할 수 있기 때문\n",
    "              - 그러므로 사용자가 필요한 예측기룰 수행해야 함\n",
    "              - 구현도 어렵지 않음\n",
    "- ex. KNeighborClassifier 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25b77776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=50)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=50)\n",
    "knn.fit(dbscan.components_, dbscan.labels_[dbscan.core_sample_indices_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b63b67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 3, 1, 0]),\n",
       " array([[0.  , 0.76, 0.  , 0.24, 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.04, 0.  , 0.86, 0.  , 0.  , 0.1 , 0.  ],\n",
       "        [0.22, 0.42, 0.06, 0.  , 0.2 , 0.1 , 0.  , 0.  ],\n",
       "        [1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플 몇 개를 전달해 어떤 클러스터에 속할 가능성이 높은지 예측하고 각 클러스터에 대한 확률 추정\n",
    "X_new = np.array([[-0.5, 0], [0, 0.5], [1, -0.1], [2, 1]])\n",
    "knn.predict(X_new), knn.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0a630",
   "metadata": {},
   "source": [
    "- 분류기를 핵심 샘플에서만 훈련헀지만 모든 샘플에서 훈련하거나 이상치를 제외할 수도 있음\n",
    "    * 선택은 최종 작업의 성능에 따라 결정\n",
    "\n",
    "- 이 결정 경계가 [그림 9-15]에 나타남\n",
    "    * 덧셈 기호는 X_new에 있는 샘플 4개를 표시\n",
    "    * 훈련세트에 이상치가 없기 때문에 클러스터가 멀리 떨어져 있더라도 분류기는 항상 클러스터 한 개를 선택함\n",
    "    * 최대 거리를 사용하면 두 클러스터에서 멀리 떨어진 샘플을 이상치로 간단히 분류 가능\n",
    "        - *KNeighborsClassifier* 의 *kneighbors()* 메서드를 사용함\n",
    "            * 이 메서드에 샘플을 전달하면 훈련 세트에서 가장 가까운 k개 이웃의 거리와 인덱스를 반환 (k개 열을 가진 행렬 2개를 반환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7802c0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  6,  5, -1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dist, y_pred_idx = knn.kneighbors(X_new, n_neighbors=1)\n",
    "y_pred = dbscan.labels_[dbscan.core_sample_indices_][y_pred_idx]\n",
    "y_pred[y_dist > 0.2] = -1\n",
    "y_pred.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2fdbb0",
   "metadata": {},
   "source": [
    "- DBSCAN은 매우 간단하지만 강력한 알고리즘\n",
    "    * 클러스터의 모양과 개수에 상관없이 감지할 수 있는 능력이 있음\n",
    "    * 이상치에 안정적이고 하이퍼파라미터가 2개 (*eps*, *min_samples*)\n",
    "    * 그러나 클러스터 간의 밀집도가 크게 다르면 모든 클러스터를 올바르게 잡아내는 것이 불가능함\n",
    "    * 계산 복잡도 : $O(m log m)$\n",
    "        - 샘플 개수에 대해 거의 선형적으로 증가\n",
    "        - 그러나 Sklearn의 구현은 *eps*가 커지면 $O(m^2)$만큼 메모리가 필요함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6374597f",
   "metadata": {},
   "source": [
    "#### 9.1.7 다른 군집 알고리즘\n",
    "##### 1. 병합 군집\n",
    "- 클러스터 계층을 밑바닥부터 위로 쌓아 구성\n",
    "    * 물 위를 떠다니는 작은 방울들이 점차 붙어 나중에는 하나의 커다란 방울이 되는 것과 유사함\n",
    "- 반복마다 병합 군집이 인접한 클러스터 쌍을 연결 (처음에는 샘플 1개에서 시작)\n",
    "- 병합된 클러스터 쌍을 트리로 모두 그리면 클러스터의 이진 트리를 얻을 수 있음\n",
    "    * 이 트리의 리프는 개별 샘플임\n",
    "- 대규모 샘플과 클러스터에 잘 확장되며 다양한 형태의 클러스터를 감지할 수 있음\n",
    "- 특정 클러스터 개수를 선택하는데 도움이 되는 유용한 클러스터 트리를 만들 수 있음\n",
    "    * 이는 어떤 짝 거리 (두 클러스터 간의 거리?) 와도 사용할 수 있음\n",
    "- 이웃한 샘플 간의 거리를 담은 $m\\times m$ 크기 희소 행렬을 연결 행렬로 전달하는 식으로 대규모 샘플에도 잘 적용할 수 있음\n",
    "    * *sklearn.neighbors.kneighbors_graph()* 함수가 반환한 값 사용\n",
    "- 연결 행렬이 없으면 대규모 데이터셋으로 확장하기 어려움\n",
    " \n",
    "\n",
    "##### 2. BIRCH (Balanced Iterative Reducing and Clustering using Hierachies)\n",
    "- 대규모 데이터셋을 위해 특별히 고안된 알고리즘\n",
    "- 특성 개수가 너무 많지 않다면 (20개 이하) 배치 k-평균보다 빠르고 비슷한 결과를 만듬\n",
    "- 훈련 과정에서 새로운 샘플을 클러스터에 빠르게 할당할 수 있는 정보를 담은 트리 구조를 만듬\n",
    "- 이 트리에 모든 샘플을 저장하지 않기 때문에 제한된 메모리를 사용해 대용량 데이터셋을 다룰 수 있음\n",
    "\n",
    "##### 3. 평균-이동\n",
    "- 먼저 각 샘플을 중심으로 하는 원을 그림\n",
    "- 그 다음 원마다 안에 포함된 모든 샘플의 평균을 구함\n",
    "- 그리고 원의 중심을 평균점으로 이동시킴\n",
    "- 모든 점이 움직이지 않을 때까지 평균-이동을 계속함\n",
    "    * 원의 중심이 포함된 샘플의 평균점일 때까지 지속\n",
    "- 평균-이동은 지역의 **최대 밀도**를 찾을 때까지 높은 쪽으로 원을 이동시킴\n",
    "    * 동일한 지역에 (또는 충분히 가깝게) 안착한 원에 있는 모든 샘플은 동일한 클러스터가 됨\n",
    "- DBSCAN과 유사한 특징 존재\n",
    "    1. 모양이나 개수에 상관 없이 클러스터를 찾을 수 있음\n",
    "    2. 하이퍼파라미터도 매우 적음 (**Bandwidth**라고 부르는 원 반경 1개)\n",
    "    3. 국부적인 밀집도 추정에 의존\n",
    "- 그러나 DBSCAN과 달리 평균-이동은 클러스터 내부 밀집도가 불균형할 때 여러개로 나누는 경향이 있음\n",
    "- 계산 복잡도는 $O(m^2)$임\n",
    "    * 대규모 데이터셋에는 적합하지 않음\n",
    "\n",
    "##### 4. 유사도 전파\n",
    "- 투표 방식을 사용\n",
    "    * 샘플은 자신을 대표할 수 있는 비슷한 샘플에 투표함\n",
    "- 알고리즘이 수렴하면 각 대표와 투표한 샘플이 클러스터를 형성\n",
    "- 크기가 다른 여러개의 클러스터를 감지할 수 있음\n",
    "- 계산 복잡도는 $O(m^2)$임\n",
    "    * 대규모 데이터셋에는 적합하지 않음\n",
    "\n",
    "##### 5. 스펙트럼 군집\n",
    "- 샘플 사이의 유사도 행렬을 받아 저차원 임베딩을 만듬 (-> 차원 축소)\n",
    "- 그 다음 이 저차원 공간에서 또 다른 군집 알고리즘 사용\n",
    "    * Sklearn의 구현에서는 k-평균을 사용\n",
    "- 복잡한 클러스터 구조를 감지하고 그래프 컷을 찾는 데 사용할 수 있음\n",
    "    * ex. 소셜 네트워크에서 친구의 클러스터를 찾음\n",
    "- 샘플 갯수가 많으면 잘 적용되지 않고 클러스터의 크기가 매우 다르면 잘 동작하지 않음\n",
    "\n",
    "## Next -> 밀집도 추정, 군집, 이상치 탐지에 사용할 수 있는 가우시안 혼합 모델"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
